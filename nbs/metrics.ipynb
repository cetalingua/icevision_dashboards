{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics\n",
    "> Metrics for the evaluation of models are defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from typing import Union, Optional, Any, Iterable, Callable\n",
    "import os\n",
    "import shutil\n",
    "from abc import ABC, abstractmethod\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "from icevision_dashboards.utils import string_to_erles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from icevision_dashboards.data import ObjectDetectionResultsDataset, InstanceSegmentationResultsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class APObjectDetection:\n",
    "    \"\"\"A faster implementaiton for the (m)AP scores.\"\"\"\n",
    "    def __init__(self, data, ious=None):\n",
    "        self.data = data\n",
    "        self.ious = ious if ious is not None else np.arange(0.5, 1, 0.05).round(2)\n",
    "        self.metric_data = self.get_metric_data()\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_iou(pred_box, gt_box):\n",
    "        px1, py1, px2, py2 = pred_box\n",
    "        tx1, ty1, tx2, ty2 = gt_box\n",
    "\n",
    "        # return 0 if the boxes don't intersect\n",
    "        if (tx2 < px1 or px2 < tx1 or ty2 < py1 or py2 < ty1):\n",
    "            return 0, 0, 0, 0\n",
    "        else:\n",
    "            lower_x = max(tx1, px1)\n",
    "            upper_x = min(tx2, px2)\n",
    "            lower_y = max(ty1, py1)\n",
    "            upper_y = min(ty2, py2)\n",
    "            intersection_area = (upper_x-lower_x) * (upper_y-lower_y)\n",
    "            gt_box_area = (tx2-tx1) * (ty2-ty1)\n",
    "            pred_box_area = (px2-px1) * (py2-py1)\n",
    "            iou = intersection_area / (gt_box_area + pred_box_area - intersection_area)\n",
    "            return iou, pred_box_area, gt_box_area, intersection_area\n",
    "    \n",
    "    def get_image_stats(self, gt_boxes, pred_boxes, iou_threshold):\n",
    "        \"\"\"\n",
    "        Returns: tp, fp, fn, :if additional_stats: x_center_offsets, y_center_offsets, center_distances, used_gt_box_areas_normalized, used_pred_box_areas_normalized, used_gt_box_areas_normalized, used_pred_box_areas_normalized\n",
    "        \"\"\"\n",
    "        if pred_boxes is None:\n",
    "            return 0,  0, len(gt_boxes), [], [], [], [], [], [], []\n",
    "        if len(gt_boxes) == 0:\n",
    "            return 0, len(pred_boxes), 0, [], [], [], [], [], [], []\n",
    "        else:\n",
    "            # calculate ious and log their mapping with box indices\n",
    "            gt_box_indices = []\n",
    "            pred_box_indices = []\n",
    "            ious = []\n",
    "            gt_box_areas = []\n",
    "            pred_box_areas = []\n",
    "            intersection_areas = []\n",
    "            for pred_box_index, pred_box in enumerate(pred_boxes):\n",
    "                for gt_box_index, gt_box in enumerate(gt_boxes):\n",
    "                    iou, pred_box_area, gt_box_area, intersection_area = self.calculate_iou(pred_box, gt_box)\n",
    "                    if iou >= iou_threshold:\n",
    "                        gt_box_indices.append(gt_box_index)\n",
    "                        pred_box_indices.append(pred_box_index)\n",
    "                        ious.append(iou)\n",
    "                        pred_box_areas.append(pred_box_area)\n",
    "                        gt_box_areas.append(gt_box_area)\n",
    "                        intersection_areas.append(intersection_area)\n",
    "\n",
    "            # check if any hits happend\n",
    "            if len(ious) == 0:\n",
    "                return 0, len(pred_boxes), len(gt_boxes), [], [], [], [], [], [], []\n",
    "            else:\n",
    "                # select matches based on iou\n",
    "                indices_descending = np.argsort(ious)[::-1]\n",
    "                gt_match_indices = []\n",
    "                pred_match_indices = []\n",
    "                x_center_offsets = []\n",
    "                y_center_offsets = []\n",
    "                center_distances = []\n",
    "                unused_gt_box_areas_normalized = []\n",
    "                unused_pred_box_areas_normalized = []\n",
    "                used_gt_box_areas_normalized = []\n",
    "                used_pred_box_areas_normalized = []\n",
    "                for index in indices_descending:\n",
    "                    gt_index = gt_box_indices[index]\n",
    "                    pred_index = pred_box_indices[index]\n",
    "                    if (gt_index not in gt_match_indices) and (pred_index not in pred_match_indices):\n",
    "                        gt_match_indices.append(gt_index)\n",
    "                        pred_match_indices.append(pred_index)\n",
    "                        # calculate additional stats\n",
    "                        pred_box_x1, pred_box_y1, pred_box_x2, pred_box_y2 = pred_boxes[pred_box_index]\n",
    "                        gt_box_x1, gt_box_y1, gt_box_x2, gt_box_y2 = gt_boxes[gt_box_index]\n",
    "\n",
    "                        x_center_offset = ((pred_box_x1+pred_box_x2)-(gt_box_x1+gt_box_x2))/2\n",
    "                        y_center_offset = ((pred_box_y1+pred_box_y2)-(gt_box_y1+gt_box_y2))/2\n",
    "                        x_center_offsets.append(x_center_offset)\n",
    "                        y_center_offsets.append(y_center_offset)\n",
    "                        center_distances.append((x_center_offset**2+y_center_offset**2)**0.5)\n",
    "                        unused_gt_box_areas_normalized.append((gt_box_areas[index]-intersection_areas[index])/gt_box_areas[index])\n",
    "                        unused_pred_box_areas_normalized.append((pred_box_areas[index]-intersection_areas[index])/pred_box_areas[index])\n",
    "                        used_gt_box_areas_normalized.append(intersection_areas[index]/gt_box_areas[index])\n",
    "                        used_pred_box_areas_normalized.append(intersection_areas[index]/pred_box_areas[index])\n",
    "                        \n",
    "                return len(gt_match_indices), len(pred_boxes) - len(pred_match_indices), len(gt_boxes) - len(gt_match_indices), x_center_offsets, y_center_offsets, center_distances, unused_gt_box_areas_normalized, unused_pred_box_areas_normalized, used_gt_box_areas_normalized, used_pred_box_areas_normalized\n",
    "\n",
    "    def get_precision_and_recall(self, gt, pred, iou):\n",
    "        \"\"\"gt and pred need to be sored dicts with the lowest score being the first entry\"\"\"\n",
    "        tps, fps, fns = [], [], []\n",
    "        precisions, recalls, score_thresholds = [], [], []\n",
    "        x_center_offsets, y_center_offsets, center_distances, unused_gt_box_areas_normalized, unused_pred_box_areas_normalized, used_gt_box_areas_normalized, used_pred_box_areas_normalized = [], [], [], [], [], [], []\n",
    "\n",
    "        if pred is None:\n",
    "            return {\n",
    "                \"tp\": np.array([0]), \"fp\": [sum(len(gt_boxes) for gt_boxes in gt.values())], \"fn\": np.array([0]), \n",
    "                \"precision\": np.array([0]), \"recall\": np.array([0]), \"scores\": np.array([0]),\n",
    "                \"ap11\": 0, \"ap\": 0, \"monotonic_recalls\": np.array([0]), \"monotonic_precisions\": np.array([0]),\n",
    "                \"ap11_recalls\": np.array([0]), \"ap11_precisions\": np.array([0]), \"x_center_offsets\": np.array([0]),\n",
    "                \"y_center_offsets\": np.array([0]), \"center_distances\": np.array([0]),\n",
    "                \"unused_gt_box_areas_normalized\": np.array([0]), \"unused_pred_box_areas_normalized\": np.array([0]),\n",
    "                \"used_gt_box_areas_normalized\": np.array([0]), \"used_pred_box_areas_normalized\": np.array([0])\n",
    "            }\n",
    "\n",
    "        scores = list(pred.keys())\n",
    "        pred_boxes = list(pred.values())\n",
    "        # loop over scores to calculate statistics for the score\n",
    "        for score_index, score in enumerate(scores):\n",
    "            score_tp, score_fp, score_fn = 0, 0, 0\n",
    "            score_x_center_offsets, score_y_center_offsets, score_center_distances, score_unused_gt_box_areas_normalized, score_unused_pred_box_areas_normalized = [], [], [], [], []\n",
    "            score_used_gt_box_areas_normalized, score_used_pred_box_areas_normalized = [], []\n",
    "            # create dict with active predicitons (prediction with the same or higher score)\n",
    "            active_preds = {}\n",
    "            for pred_entry in pred_boxes[score_index:]:\n",
    "                for filename, bbox in zip(pred_entry[\"filename\"], pred_entry[\"bboxes\"]):\n",
    "                    if filename not in active_preds.keys():\n",
    "                        active_preds[filename] = [bbox]\n",
    "                    else:\n",
    "                        active_preds[filename].append(bbox)\n",
    "            # loop over gt images\n",
    "            for filename, image_gt_boxes in gt.items():\n",
    "                img_tp, img_fp, img_fn, img_x_center_offsets, img_y_center_offsets, img_center_distances, img_unused_gt_box_areas_normalized, img_unused_pred_box_areas_normalized, img_used_gt_box_areas_normalized, img_used_pred_box_areas_normalized = self.get_image_stats(image_gt_boxes, active_preds.get(filename, None), iou)\n",
    "                score_tp += img_tp\n",
    "                score_fp += img_fp\n",
    "                score_fn += img_fn\n",
    "                score_x_center_offsets += img_x_center_offsets\n",
    "                score_y_center_offsets += img_y_center_offsets\n",
    "                score_center_distances += img_center_distances\n",
    "                score_unused_gt_box_areas_normalized += img_unused_gt_box_areas_normalized\n",
    "                score_unused_pred_box_areas_normalized += img_unused_pred_box_areas_normalized\n",
    "                score_used_gt_box_areas_normalized += img_used_gt_box_areas_normalized\n",
    "                score_used_pred_box_areas_normalized += img_used_pred_box_areas_normalized\n",
    "            # calculate precision and recall for the threshold\n",
    "            score_precision = score_tp/(score_tp + score_fp) if score_tp + score_fp > 0 else 0\n",
    "            score_recall = score_tp/(score_tp + score_fn) if score_tp + score_fn > 0 else 0\n",
    "\n",
    "            tps.append(score_tp)\n",
    "            fps.append(score_fp)\n",
    "            fns.append(score_fn)\n",
    "            precisions.append(score_precision)\n",
    "            recalls.append(score_recall)\n",
    "            score_thresholds.append(score)\n",
    "            \n",
    "            x_center_offsets.append(score_x_center_offsets)\n",
    "            y_center_offsets.append(score_y_center_offsets)\n",
    "            center_distances.append(score_center_distances)\n",
    "            unused_gt_box_areas_normalized.append(score_unused_gt_box_areas_normalized)\n",
    "            unused_pred_box_areas_normalized.append(score_unused_pred_box_areas_normalized)\n",
    "            used_gt_box_areas_normalized.append(score_used_gt_box_areas_normalized)\n",
    "            used_pred_box_areas_normalized.append(score_used_pred_box_areas_normalized)\n",
    "\n",
    "        # convert data to np.arrays for further processing\n",
    "        tps = np.array(tps)\n",
    "        fps = np.array(fps)\n",
    "        fns = np.array(fns)\n",
    "        precisions = np.array(precisions)\n",
    "        recalls = np.array(recalls)\n",
    "        score_thresholds = np.array(score_thresholds)\n",
    "        \n",
    "        # calculate additional stats\n",
    "\n",
    "        # AP11\n",
    "        precisions_at_recall_value = []\n",
    "        for recall_value in np.linspace(0.0, 1.0, 11):\n",
    "            indices = np.argwhere(np.array(recalls) >= recall_value).flatten()\n",
    "            precision_max = max(precisions[indices]) if indices.size > 0 else 0\n",
    "            precisions_at_recall_value.append(precision_max)\n",
    "        ap11 = np.mean(precisions_at_recall_value)\n",
    "\n",
    "        #AP\n",
    "        sorted_indices = np.argsort(recalls)\n",
    "        sorted_recalls = recalls[sorted_indices]\n",
    "        sorted_precision = precisions[sorted_indices]\n",
    "        # make the precision values monotonically\n",
    "        calc_recalls = [0] + sorted_recalls.tolist() + [1]\n",
    "        calc_precisions = [0] + sorted_precision.tolist() + [0]\n",
    "        for i in range(len(calc_recalls)-2, -1, -1):\n",
    "            calc_precisions[i] = max(calc_precisions[i], calc_precisions[i+1])\n",
    "        # get indices where the recall value changes\n",
    "        changing_index_list = []\n",
    "        for i in range(1, len(calc_recalls)):\n",
    "            if calc_recalls[i] != calc_recalls[i-1]:\n",
    "                changing_index_list.append(i)\n",
    "        ap = 0.0\n",
    "        for i in changing_index_list:\n",
    "            ap += ((calc_recalls[i]-calc_recalls[i-1])*calc_precisions[i])\n",
    "\n",
    "        return {\n",
    "            \"tp\": tps, \"fp\": fps, \"fn\": fns, \"precision\": precisions, \"recall\": recalls, \"scores\": score_thresholds,\n",
    "            \"ap11\": ap11, \"ap\": ap, \"monotonic_recalls\": np.array(calc_recalls), \"monotonic_precisions\": np.array(calc_precisions),\n",
    "            \"ap11_recalls\": np.linspace(0.0, 1.0, 11), \"ap11_precisions\": np.array(precisions_at_recall_value), \"x_center_offsets\": x_center_offsets,\n",
    "            \"y_center_offsets\": y_center_offsets, \"center_distances\": center_distances, \n",
    "            \"unused_gt_box_areas_normalized\": unused_gt_box_areas_normalized, \"unused_pred_box_areas_normalized\": unused_pred_box_areas_normalized,\n",
    "            \"used_gt_box_areas_normalized\": used_gt_box_areas_normalized, \"used_pred_box_areas_normalized\": used_pred_box_areas_normalized\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_data(df):\n",
    "        ground_truth, preds = df[df[\"is_prediction\"] == False].sort_values(\"score\"), df[df[\"is_prediction\"] == True].sort_values(\"score\")\n",
    "\n",
    "        pred_dict = {}\n",
    "        for index, row in preds.iterrows():\n",
    "            if row[\"label\"] not in pred_dict.keys():\n",
    "                pred_dict[row[\"label\"]] = {row[\"score\"]: {\"bboxes\": [[row[\"bbox_xmin\"], row[\"bbox_ymin\"], row[\"bbox_xmax\"], row[\"bbox_ymax\"]]], \"filename\": [row[\"filename\"]]}}\n",
    "            else:\n",
    "                if not row[\"filename\"] in pred_dict[row[\"label\"]].keys():\n",
    "                    pred_dict[row[\"label\"]][row[\"score\"]] = {\"bboxes\": [[row[\"bbox_xmin\"], row[\"bbox_ymin\"], row[\"bbox_xmax\"], row[\"bbox_ymax\"]]], \"filename\": [row[\"filename\"]]}\n",
    "                else:\n",
    "                    pred_dict[row[\"label\"]][row[\"score\"]][\"bboxes\"].append([row[\"bbox_xmin\"], row[\"bbox_ymin\"], row[\"bbox_xmax\"], row[\"bbox_ymax\"]])\n",
    "                    pred_dict[row[\"label\"]][row[\"score\"]][\"filename\"].append(row[\"filename\"])\n",
    "\n",
    "        gt_dict = {}\n",
    "        for index, row in ground_truth.iterrows():\n",
    "            if row[\"label\"] not in gt_dict.keys():\n",
    "                gt_dict[row[\"label\"]] = {row[\"filename\"]: [[row[\"bbox_xmin\"], row[\"bbox_ymin\"], row[\"bbox_xmax\"], row[\"bbox_ymax\"]]]}\n",
    "            else:\n",
    "                if not row[\"filename\"] in gt_dict[row[\"label\"]].keys():\n",
    "                    gt_dict[row[\"label\"]][row[\"filename\"]] = [[row[\"bbox_xmin\"], row[\"bbox_ymin\"], row[\"bbox_xmax\"], row[\"bbox_ymax\"]]]\n",
    "                else:\n",
    "                    gt_dict[row[\"label\"]][row[\"filename\"]].append([row[\"bbox_xmin\"], row[\"bbox_ymin\"], row[\"bbox_xmax\"], row[\"bbox_ymax\"]])\n",
    "        return gt_dict, pred_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_data(df, filter_key_word):\n",
    "        if filter_key_word == \"AP\":\n",
    "            return df\n",
    "        elif filter_key_word == \"AP_small\":\n",
    "            return df[(df[\"area\"] < 32**2)]\n",
    "        elif filter_key_word == \"AP_medium\":\n",
    "            return df[((32**2 <= df[\"area\"]) & (df[\"area\"] < 96**2))]\n",
    "        elif filter_key_word == \"AP_large\":\n",
    "            return df[96**2 <= df[\"area\"]]\n",
    "        \n",
    "    def get_metric_data(self):\n",
    "        analysis_data = {}\n",
    "        for analysis_type in [\"AP\", \"AP_small\", \"AP_medium\", \"AP_large\"]:\n",
    "            filtered_df = self.filter_data(self.data, analysis_type)\n",
    "            gt_dict, pred_dict = self.prepare_data(filtered_df)\n",
    "            class_names = gt_dict.keys()\n",
    "            class_data = {}\n",
    "            for class_name in class_names:\n",
    "                iou_data = {}\n",
    "                for iou in self.ious:\n",
    "                    res = self.get_precision_and_recall(gt_dict[class_name], pred_dict.get(class_name, None), iou)\n",
    "                    iou_data[iou] = res\n",
    "                iou_data[\"ap\"] = np.array([iou[\"ap\"] for iou in iou_data.values()]).mean()\n",
    "                class_data[class_name] = iou_data\n",
    "            class_data[\"map\"] = np.array([class_entry[\"ap\"] for class_entry in class_data.values()]).mean() if len(class_data.values()) > 0 else 0\n",
    "            analysis_data[analysis_type] = class_data\n",
    "        return analysis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_object_detection_record_dataset = ObjectDetectionResultsDataset.load(\"test_data/object_detection_result_ds.dat\")\n",
    "test_detection_stats = APObjectDetection(test_object_detection_record_dataset.base_data, np.arange(0.5, 1, 0.05).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class APInstanceSegmentation:\n",
    "    \"\"\"A faster implementaiton for the (m)AP scores.\"\"\"\n",
    "    def __init__(self, data, ious=None):\n",
    "        self.data = data\n",
    "        self.ious = ious if ious is not None else np.arange(0.5, 1, 0.05).round(2)\n",
    "        self.metric_data = self.get_metric_data()\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_iou(pred_mask_array, gt_mask_array):\n",
    "        mask_combination = pred_mask_array + gt_mask_array\n",
    "        intersection_area = (mask_combination == 2).sum()\n",
    "        non_intersecting_area = (mask_combination == 1).sum()\n",
    "        iou = intersection_area / (non_intersecting_area + intersection_area)\n",
    "        return iou, intersection_area\n",
    "    \n",
    "    def get_image_stats(self, gt_masks, pred_masks, iou_threshold):\n",
    "        \"\"\"\n",
    "        Returns: tp, fp, fn, :if additional_stats: x_center_offsets, y_center_offsets, center_distances, used_gt_mask_areas_normalized, used_pred_mask_areas_normalized, used_gt_mask_areas_normalized, used_pred_mask_areas_normalized\n",
    "        \"\"\"\n",
    "        if pred_masks is None:\n",
    "            return 0,  0, len(gt_masks[\"masks\"]), [], [], [], [], [], [], []\n",
    "        if len(gt_masks) == 0:\n",
    "            return 0, len(pred_masks[\"masks\"]), 0, [], [], [], [], [], [], []\n",
    "        else:\n",
    "            # calculate ious and log their mapping with mask indices\n",
    "            gt_mask_indices = []\n",
    "            pred_mask_indices = []\n",
    "            ious = []\n",
    "            gt_mask_areas = []\n",
    "            pred_mask_areas = []\n",
    "            intersection_areas = []\n",
    "            for pred_mask_index, (pred_mask, pred_area) in enumerate(zip(pred_masks[\"masks\"], pred_masks[\"areas\"])):\n",
    "                for gt_mask_index, (gt_mask, gt_area) in enumerate(zip(gt_masks[\"masks\"], gt_masks[\"areas\"])):\n",
    "                    iou, intersection_area = self.calculate_iou(pred_mask, gt_mask)\n",
    "                    if iou >= iou_threshold:\n",
    "                        gt_mask_indices.append(gt_mask_index)\n",
    "                        pred_mask_indices.append(pred_mask_index)\n",
    "                        ious.append(iou)\n",
    "                        pred_mask_areas.append(pred_area)\n",
    "                        gt_mask_areas.append(gt_area)\n",
    "                        intersection_areas.append(intersection_area)\n",
    "            # check if any hits happend\n",
    "            if len(ious) == 0:\n",
    "                return 0, len(pred_masks[\"masks\"]), len(gt_masks[\"masks\"]), [], [], [], [], [], [], []\n",
    "            else:\n",
    "                # select matches based on iou\n",
    "                indices_descending = np.argsort(ious)[::-1]\n",
    "                gt_match_indices = []\n",
    "                pred_match_indices = []\n",
    "                x_center_offsets = []\n",
    "                y_center_offsets = []\n",
    "                center_distances = []\n",
    "                unused_gt_mask_areas_normalized = []\n",
    "                unused_pred_mask_areas_normalized = []\n",
    "                used_gt_mask_areas_normalized = []\n",
    "                used_pred_mask_areas_normalized = []\n",
    "                for index in indices_descending:\n",
    "                    gt_index = gt_mask_indices[index]\n",
    "                    pred_index = pred_mask_indices[index]\n",
    "                    if (gt_index not in gt_match_indices) and (pred_index not in pred_match_indices):\n",
    "                        gt_match_indices.append(gt_index)\n",
    "                        pred_match_indices.append(pred_index)\n",
    "                        # calculate additional stats\n",
    "                        pred_mask_array = pred_masks[\"masks\"][pred_mask_index]\n",
    "                        pred_mask_y_indices, pred_mask_x_indices = np.where(pred_mask_array == 1)\n",
    "                        pred_mask_x1, pred_mask_y1, pred_mask_x2, pred_mask_y2 = pred_mask_x_indices[0], pred_mask_x_indices[-1], pred_mask_y_indices[0], pred_mask_y_indices[-1]\n",
    "                        \n",
    "                        gt_mask_array = gt_masks[\"masks\"][gt_mask_index]\n",
    "                        gt_mask_y_indices, gt_mask_x_indices = np.where(gt_mask_array == 1)\n",
    "                        gt_mask_x1, gt_mask_y1, gt_mask_x2, gt_mask_y2 = gt_mask_x_indices[0], gt_mask_x_indices[-1], gt_mask_y_indices[0], gt_mask_y_indices[-1]\n",
    "\n",
    "                        x_center_offset = ((pred_mask_x1+pred_mask_x2)-(gt_mask_x1+gt_mask_x2))/2\n",
    "                        y_center_offset = ((pred_mask_y1+pred_mask_y2)-(gt_mask_y1+gt_mask_y2))/2\n",
    "                        x_center_offsets.append(x_center_offset)\n",
    "                        y_center_offsets.append(y_center_offset)\n",
    "                        center_distances.append((x_center_offset**2+y_center_offset**2)**0.5)\n",
    "                        unused_gt_mask_areas_normalized.append((gt_mask_areas[index]-intersection_areas[index])/gt_mask_areas[index])\n",
    "                        unused_pred_mask_areas_normalized.append((pred_mask_areas[index]-intersection_areas[index])/pred_mask_areas[index])\n",
    "                        used_gt_mask_areas_normalized.append(intersection_areas[index]/gt_mask_areas[index])\n",
    "                        used_pred_mask_areas_normalized.append(intersection_areas[index]/pred_mask_areas[index])\n",
    "\n",
    "                return len(gt_match_indices), len(pred_masks[\"masks\"]) - len(pred_match_indices), len(gt_masks[\"masks\"]) - len(gt_match_indices), x_center_offsets, y_center_offsets, center_distances, unused_gt_mask_areas_normalized, unused_pred_mask_areas_normalized, used_gt_mask_areas_normalized, used_pred_mask_areas_normalized\n",
    "\n",
    "    def get_precision_and_recall(self, gt, pred, iou):\n",
    "        \"\"\"gt and pred need to be sored dicts with the lowest score being the first entry\"\"\"\n",
    "        tps, fps, fns = [], [], []\n",
    "        precisions, recalls, score_thresholds = [], [], []\n",
    "        x_center_offsets, y_center_offsets, center_distances, unused_gt_mask_areas_normalized, unused_pred_mask_areas_normalized, used_gt_mask_areas_normalized, used_pred_mask_areas_normalized = [], [], [], [], [], [], []\n",
    "\n",
    "        if pred is None:\n",
    "            return {\n",
    "                \"tp\": np.array([0]), \"fp\": [sum(len(gt_masks) for gt_masks in gt.values())], \"fn\": np.array([0]), \n",
    "                \"precision\": np.array([0]), \"recall\": np.array([0]), \"scores\": np.array([0]),\n",
    "                \"ap11\": 0, \"ap\": 0, \"monotonic_recalls\": np.array([0]), \"monotonic_precisions\": np.array([0]),\n",
    "                \"ap11_recalls\": np.array([0]), \"ap11_precisions\": np.array([0]), \"x_center_offsets\": np.array([0]),\n",
    "                \"y_center_offsets\": np.array([0]), \"center_distances\": np.array([0]),\n",
    "                \"unused_gt_mask_areas_normalized\": np.array([0]), \"unused_pred_mask_areas_normalized\": np.array([0]),\n",
    "                \"used_gt_mask_areas_normalized\": np.array([0]), \"used_pred_mask_areas_normalized\": np.array([0])\n",
    "            }, iou\n",
    "\n",
    "        scores = list(pred.keys())\n",
    "        pred_masks = list(pred.values())\n",
    "        # loop over scores to calculate statistics for the score\n",
    "        for score_index, score in enumerate(scores):\n",
    "            score_tp, score_fp, score_fn = 0, 0, 0\n",
    "            score_x_center_offsets, score_y_center_offsets, score_center_distances, score_unused_gt_mask_areas_normalized, score_unused_pred_mask_areas_normalized = [], [], [], [], []\n",
    "            score_used_gt_mask_areas_normalized, score_used_pred_mask_areas_normalized = [], []\n",
    "            # create dict with active predicitons (prediction with the same or higher score)\n",
    "            active_preds = {\"masks\": [], \"areas\": []}\n",
    "            for pred_entry in pred_masks[score_index:]:\n",
    "                for filename, mask, area in zip(pred_entry[\"filename\"], pred_entry[\"masks\"], pred_entry[\"areas\"]):\n",
    "                    if filename not in active_preds.keys():\n",
    "                        active_preds[filename] = {\"masks\": [mask], \"areas\": [area]}\n",
    "                    else:\n",
    "                        active_preds[filename][\"masks\"].append(mask)\n",
    "                        active_preds[filename][\"areas\"].append(area)\n",
    "            # loop over gt images\n",
    "            for filename, image_gt_masks in gt.items():\n",
    "                img_tp, img_fp, img_fn, img_x_center_offsets, img_y_center_offsets, img_center_distances, img_unused_gt_mask_areas_normalized, img_unused_pred_mask_areas_normalized, img_used_gt_mask_areas_normalized, img_used_pred_mask_areas_normalized = self.get_image_stats(image_gt_masks, active_preds.get(filename, None), iou)\n",
    "                score_tp += img_tp\n",
    "                score_fp += img_fp\n",
    "                score_fn += img_fn\n",
    "                score_x_center_offsets += img_x_center_offsets\n",
    "                score_y_center_offsets += img_y_center_offsets\n",
    "                score_center_distances += img_center_distances\n",
    "                score_unused_gt_mask_areas_normalized += img_unused_gt_mask_areas_normalized\n",
    "                score_unused_pred_mask_areas_normalized += img_unused_pred_mask_areas_normalized\n",
    "                score_used_gt_mask_areas_normalized += img_used_gt_mask_areas_normalized\n",
    "                score_used_pred_mask_areas_normalized += img_used_pred_mask_areas_normalized\n",
    "            # calculate precision and recall for the threshold\n",
    "            score_precision = score_tp/(score_tp + score_fp) if score_tp + score_fp > 0 else 0\n",
    "            score_recall = score_tp/(score_tp + score_fn) if score_tp + score_fn > 0 else 0\n",
    "            \n",
    "            tps.append(score_tp)\n",
    "            fps.append(score_fp)\n",
    "            fns.append(score_fn)\n",
    "            precisions.append(score_precision)\n",
    "            recalls.append(score_recall)\n",
    "            score_thresholds.append(score)\n",
    "            \n",
    "            x_center_offsets.append(score_x_center_offsets)\n",
    "            y_center_offsets.append(score_y_center_offsets)\n",
    "            center_distances.append(score_center_distances)\n",
    "            unused_gt_mask_areas_normalized.append(score_unused_gt_mask_areas_normalized)\n",
    "            unused_pred_mask_areas_normalized.append(score_unused_pred_mask_areas_normalized)\n",
    "            used_gt_mask_areas_normalized.append(score_used_gt_mask_areas_normalized)\n",
    "            used_pred_mask_areas_normalized.append(score_used_pred_mask_areas_normalized)\n",
    "\n",
    "        # convert data to np.arrays for further processing\n",
    "        tps = np.array(tps)\n",
    "        fps = np.array(fps)\n",
    "        fns = np.array(fns)\n",
    "        precisions = np.array(precisions)\n",
    "        recalls = np.array(recalls)\n",
    "        score_thresholds = np.array(score_thresholds)\n",
    "        \n",
    "        # calculate additional stats\n",
    "\n",
    "        # AP11\n",
    "        precisions_at_recall_value = []\n",
    "        for recall_value in np.linspace(0.0, 1.0, 11):\n",
    "            indices = np.argwhere(np.array(recalls) >= recall_value).flatten()\n",
    "            precision_max = max(precisions[indices]) if indices.size > 0 else 0\n",
    "            precisions_at_recall_value.append(precision_max)\n",
    "        ap11 = np.mean(precisions_at_recall_value)\n",
    "\n",
    "        #AP\n",
    "        sorted_indices = np.argsort(recalls)\n",
    "        sorted_recalls = recalls[sorted_indices]\n",
    "        sorted_precision = precisions[sorted_indices]\n",
    "        # make the prefrom joblib import Parallel, delayedcision values monotonically\n",
    "        calc_recalls = [0] + sorted_recalls.tolist() + [1]\n",
    "        calc_precisions = [0] + sorted_precision.tolist() + [0]\n",
    "        for i in range(len(calc_recalls)-2, -1, -1):\n",
    "            calc_precisions[i] = max(calc_precisions[i], calc_precisions[i+1])\n",
    "        # get indices where the recall value changes\n",
    "        changing_index_list = []\n",
    "        for i in range(1, len(calc_recalls)):\n",
    "            if calc_recalls[i] != calc_recalls[i-1]:\n",
    "                changing_index_list.append(i)\n",
    "        ap = 0.0\n",
    "        for i in changing_index_list:\n",
    "            ap += ((calc_recalls[i]-calc_recalls[i-1])*calc_precisions[i])\n",
    "\n",
    "        return {\n",
    "            \"tp\": tps, \"fp\": fps, \"fn\": fns, \"precision\": precisions, \"recall\": recalls, \"scores\": score_thresholds,\n",
    "            \"ap11\": ap11, \"ap\": ap, \"monotonic_recalls\": np.array(calc_recalls), \"monotonic_precisions\": np.array(calc_precisions),\n",
    "            \"ap11_recalls\": np.linspace(0.0, 1.0, 11), \"ap11_precisions\": np.array(precisions_at_recall_value), \"x_center_offsets\": x_center_offsets,\n",
    "            \"y_center_offsets\": y_center_offsets, \"center_distances\": center_distances, \n",
    "            \"unused_gt_mask_areas_normalized\": unused_gt_mask_areas_normalized, \"unused_pred_mask_areas_normalized\": unused_pred_mask_areas_normalized,\n",
    "            \"used_gt_mask_areas_normalized\": used_gt_mask_areas_normalized, \"used_pred_mask_areas_normalized\": used_pred_mask_areas_normalized\n",
    "        }, iou\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_data(df):\n",
    "        ground_truth, preds = df[df[\"is_prediction\"] == False].sort_values(\"score\"), df[df[\"is_prediction\"] == True].sort_values(\"score\")\n",
    "\n",
    "        pred_dict = {}\n",
    "        for index, row in preds.iterrows():\n",
    "            if row[\"label\"] not in pred_dict.keys():\n",
    "                pred_dict[row[\"label\"]] = {row[\"score\"]: {\"masks\": [mask_utils.decode([string_to_erles(row[\"erles_corrected\"])]).transpose(2, 0, 1)[0,:,:]], \"filename\": [row[\"filename\"]], \"areas\": [row[\"mask_area\"]]}}\n",
    "            else:\n",
    "                if not row[\"filename\"] in pred_dict[row[\"label\"]].keys():\n",
    "                    pred_dict[row[\"label\"]][row[\"score\"]] = {\"masks\": [mask_utils.decode([string_to_erles(row[\"erles_corrected\"])]).transpose(2, 0, 1)[0,:,:]], \"filename\": [row[\"filename\"]], \"areas\": [row[\"mask_area\"]]}\n",
    "                else:\n",
    "                    pred_dict[row[\"label\"]][row[\"score\"]][\"maskes\"].append(mask_utils.decode([string_to_erles(row[\"erles_corrected\"])]).transpose(2, 0, 1)[0,:,:])\n",
    "                    pred_dict[row[\"label\"]][row[\"score\"]][\"filename\"].append(row[\"filename\"])\n",
    "                    pred_dict[row[\"label\"]][row[\"score\"]][\"areas\"].append(row[\"mask_area\"])\n",
    "\n",
    "        gt_dict = {}\n",
    "        for index, row in ground_truth.iterrows():\n",
    "            if row[\"label\"] not in gt_dict.keys():\n",
    "                gt_dict[row[\"label\"]] = {row[\"filename\"]: {\"masks\": [mask_utils.decode([string_to_erles(row[\"erles_corrected\"])]).transpose(2, 0, 1)[0,:,:]], \"areas\": [row[\"mask_area\"]]}}\n",
    "            else:\n",
    "                if not row[\"filename\"] in gt_dict[row[\"label\"]].keys():\n",
    "                    gt_dict[row[\"label\"]][row[\"filename\"]] = {\"masks\": [mask_utils.decode([string_to_erles(row[\"erles_corrected\"])]).transpose(2, 0, 1)[0,:,:]], \"areas\": [row[\"mask_area\"]]}\n",
    "                else:\n",
    "                    gt_dict[row[\"label\"]][row[\"filename\"]][\"masks\"].append(mask_utils.decode([string_to_erles(row[\"erles_corrected\"])]).transpose(2, 0, 1)[0,:,:])\n",
    "                    gt_dict[row[\"label\"]][row[\"filename\"]][\"areas\"].append(row[\"mask_area\"])\n",
    "        return gt_dict, pred_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_data(df, filter_key_word):\n",
    "        if filter_key_word == \"AP\":\n",
    "            return df\n",
    "        elif filter_key_word == \"AP_small\":\n",
    "            return df[(df[\"bbox_area\"] < 32**2)]\n",
    "        elif filter_key_word == \"AP_medium\":\n",
    "            return df[((32**2 <= df[\"bbox_area\"]) & (df[\"bbox_area\"] < 96**2))]\n",
    "        elif filter_key_word == \"AP_large\":\n",
    "            return df[96**2 <= df[\"bbox_area\"]]\n",
    "        \n",
    "    def get_metric_data(self):\n",
    "        analysis_data = {}\n",
    "        for analysis_type in [\"AP\", \"AP_small\", \"AP_medium\", \"AP_large\"]:\n",
    "            filtered_df = self.filter_data(self.data, analysis_type)\n",
    "            gt_dict, pred_dict = self.prepare_data(filtered_df)\n",
    "            class_names = gt_dict.keys()\n",
    "            class_data = {}\n",
    "            for class_name in class_names:\n",
    "                iou_data = {}\n",
    "                results = Parallel(n_jobs=10)(delayed(self.get_precision_and_recall)(gt_dict[class_name], pred_dict.get(class_name, None), iou) for iou in self.ious)\n",
    "                for res in results:\n",
    "                    iou_data[res[1]] = res[0]       \n",
    "                \n",
    "                # for iou in self.ious:\n",
    "                #     res = self.get_precision_and_recall(gt_dict[class_name], pred_dict.get(class_name, None), iou)\n",
    "                #     iou_data[res[1]] = res[0]\n",
    "                    \n",
    "                iou_data[\"ap\"] = np.array([iou[\"ap\"] for iou in iou_data.values()]).mean()\n",
    "                class_data[class_name] = iou_data\n",
    "            class_data[\"map\"] = np.array([class_entry[\"ap\"] for class_entry in class_data.values()]).mean() if len(class_data.values()) > 0 else 0\n",
    "            analysis_data[analysis_type] = class_data\n",
    "        return analysis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_instance_segmentation_record_dataset = InstanceSegmentationResultsDataset.load(\"test_data/instance_segmentation_result_ds_valid.dat\")\n",
    "test_instance_segmentation_stats = APInstanceSegmentation(test_instance_segmentation_record_dataset.base_data.iloc[:10], np.arange(0.5, 1, 0.05).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
